{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=(3,3), stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=(3,3), stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=(1,3), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=(1,10), stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=(1,3), bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=(1,4), stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=1000):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=(1,3), stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=1)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=1)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=1)\n",
    "        self.linear = nn.Linear(16, num_classes)\n",
    "        self.flat = nn.Conv2d(in_channels=512, out_channels=1, kernel_size=1, stride=1)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         print(\"Input ==> \", x.size())\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "#         print(\"F.relu(self.bn1(self.conv1(x))) ==> \", x.size())\n",
    "        out = self.layer1(out)\n",
    "#         print(\"layer1 ==> \", x.size())\n",
    "        out = self.layer2(out)\n",
    "#         print(\"layer2 ==> \", x.size())\n",
    "        out = self.layer3(out)\n",
    "#         print(\"layer3 ==> \", x.size())\n",
    "        out = self.layer4(out)\n",
    "#         print(\"layer4 ==>\", out.size())\n",
    "        out = F.avg_pool2d(out, (6,4))\n",
    "        print(\"avg_pool2d ===>\", out.size())\n",
    "        # out = out.view(out.size(0), -1)\n",
    "        # print(\"out.view ===>\", out.size())\n",
    "        out = self.linear(out)\n",
    "        out = self.flat(out)\n",
    "#         print(\"Out ===>\", out.size())\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = ResNet18()\n",
    "    y = net(torch.randn(1, 3, 32, 32))\n",
    "    print(y.size())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3x2Conv =>       torch.Size([62, 64])\n",
      "max_pool_2x1 =>  torch.Size([31, 32])\n",
      "3x3Conv =>       torch.Size([31, 32])\n",
      "max_pool_2x1 =>  torch.Size([15, 16])\n",
      "3x3Conv =>       torch.Size([15, 16])\n",
      "up_trans_3x2 =>  torch.Size([31, 32])\n",
      "up_conv_3x3 =>   torch.Size([31, 32])\n",
      "up_trans_2x2 =>  torch.Size([62, 64])\n",
      "up_conv_2x3 =>   torch.Size([64, 64])\n",
      "Final =>         torch.Size([64, 64])\n",
      "avg_pool2d ===> torch.Size([1, 512, 11, 16])\n",
      "torch.Size([1, 1, 11, 1000])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image = torch.rand(1, 3, 64, 64)\n",
    "    unet = UNet(img_ch=3, output_ch=3)\n",
    "    model = ResNet34()\n",
    "    unet_out = unet(image)\n",
    "    final = model(unet_out)\n",
    "    print(final.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet(\n",
      "  (max_pool_2x2): MaxPool2d(kernel_size=(2, 1), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (down_conv_1): Sequential(\n",
      "    (0): Conv2d(10, 64, kernel_size=(3, 2), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 2), stride=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (down_conv_2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (down_conv_3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (up_trans_3): Sequential(\n",
      "    (0): ConvTranspose2d(256, 128, kernel_size=(3, 2), stride=(2, 2))\n",
      "  )\n",
      "  (up_conv_3): Sequential(\n",
      "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (up_trans_4): Sequential(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "  )\n",
      "  (up_conv_4): Sequential(\n",
      "    (0): Conv2d(128, 64, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (out): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "3x2Conv =>       torch.Size([98, 100])\n",
      "max_pool_2x1 =>  torch.Size([49, 50])\n",
      "3x3Conv =>       torch.Size([49, 50])\n",
      "max_pool_2x1 =>  torch.Size([24, 25])\n",
      "3x3Conv =>       torch.Size([24, 25])\n",
      "up_trans_3x2 =>  torch.Size([49, 50])\n",
      "up_conv_3x3 =>   torch.Size([49, 50])\n",
      "up_trans_2x2 =>  torch.Size([98, 100])\n",
      "up_conv_2x3 =>   torch.Size([100, 100])\n",
      "Final =>         torch.Size([100, 100])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import logging\n",
    "from torchvision import models\n",
    "\n",
    "def double_conv(in_c, out_c):\n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv2d(in_c, out_c, kernel_size=(3,2),padding=1 ,stride=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_c, out_c, kernel_size=(3,2), padding=1 ,stride=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True))\n",
    "    return conv\n",
    "\n",
    "def double_conv1(in_c, out_c):\n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv2d(in_c, out_c, kernel_size=(3,2),padding=1 ,stride=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_c, out_c, kernel_size=(3,2),stride=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True))\n",
    "    return conv\n",
    "\n",
    "def double_conv2(in_c, out_c):\n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv2d(in_c, out_c, kernel_size=(3,3),padding=1 ,stride=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_c, out_c, kernel_size=(3,3), padding=1 ,stride=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True))\n",
    "    return conv\n",
    "\n",
    "def double_conv3(in_c, out_c):\n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv2d(in_c, out_c, kernel_size=3,padding=1 ,stride=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_c, out_c, kernel_size=3, padding=1 ,stride=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True))\n",
    "    return conv\n",
    "\n",
    "def double_conv4(in_c, out_c):\n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv2d(in_c, out_c, kernel_size=(2, 3),padding=1 ,stride=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_c, out_c, kernel_size=(2, 3), padding=1 ,stride=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True))\n",
    "    return conv\n",
    "\n",
    "def up_conv(in_c, out_c):\n",
    "    conv = nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2))\n",
    "    return conv\n",
    "\n",
    "def up_conv1(in_c, out_c):\n",
    "    conv = nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_c, out_c, kernel_size=(3,2),stride=2))\n",
    "    return conv\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self,img_ch=1,output_ch=1):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        self.max_pool_2x2 = nn.MaxPool2d(kernel_size=(2,1), stride=2)\n",
    "        self.down_conv_1 = double_conv1(img_ch, 64)\n",
    "        self.down_conv_2 = double_conv2(64, 128)\n",
    "        self.down_conv_3 = double_conv3(128, 256)\n",
    "\n",
    "        self.up_trans_3 = up_conv1(256, 128)\n",
    "        self.up_conv_3 = double_conv2(256, 128)\n",
    "        \n",
    "        self.up_trans_4 = up_conv(128, 64)\n",
    "        self.up_conv_4 = double_conv4(128, 64)\n",
    "        \n",
    "        self.out = nn.Conv2d(\n",
    "            in_channels=64,\n",
    "            out_channels=output_ch,\n",
    "            kernel_size=1,stride=1,padding=0)\n",
    "    \n",
    "    def forward(self, image):\n",
    "        # encoder\n",
    "        #print(\"Input Image =>  \", image.size()[2:4])\n",
    "        #print(\"Encoder =================\")\n",
    "        x1 = self.down_conv_1(image)\n",
    "        print(\"3x2Conv =>      \", x1.size()[2:4])\n",
    "        x2 = self.max_pool_2x2(x1)\n",
    "        print(\"max_pool_2x1 => \", x2.size()[2:4])\n",
    "        x3 = self.down_conv_2(x2)\n",
    "        print(\"3x3Conv =>      \", x3.size()[2:4])\n",
    "        x4 = self.max_pool_2x2(x3)\n",
    "        print(\"max_pool_2x1 => \", x4.size()[2:4])\n",
    "        x5 = self.down_conv_3(x4)\n",
    "        print(\"3x3Conv =>      \", x5.size()[2:4])\n",
    "        \n",
    "        # decoder\n",
    "       # print(\"Decoder =================\")\n",
    "        x = self.up_trans_3(x5)\n",
    "        print(\"up_trans_3x2 => \", x.size()[2:4])\n",
    "\n",
    "        x = self.up_conv_3(torch.cat([x, x3], 1))\n",
    "        print(\"up_conv_3x3 =>  \", x.size()[2:4])\n",
    "\n",
    "        x = self.up_trans_4(x)\n",
    "        print(\"up_trans_2x2 => \", x.size()[2:4])\n",
    "\n",
    "        x = self.up_conv_4(torch.cat([x, x1], 1))\n",
    "        print(\"up_conv_2x3 =>  \", x.size()[2:4])\n",
    "\n",
    "        # output\n",
    "        x = self.out(x)\n",
    "        print(\"Final =>        \", x.size()[2:4])\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model = models.vgg16()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image = torch.rand(1, 10, 100, 100)\n",
    "    model = UNet(img_ch=10,output_ch=3)\n",
    "    #print(model)\n",
    "    print(model)\n",
    "    model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Image            =>  torch.Size([1, 3, 512, 512])\n",
      "Encoder =================\n",
      "Conv3x2, S1, P1        =>  torch.Size([1, 64, 510, 512])\n",
      "max_pool_2x1           =>  torch.Size([1, 64, 255, 256])\n",
      "Conv3x3, S1, P1        =>  torch.Size([1, 128, 255, 256])\n",
      "max_pool_2x1           =>  torch.Size([1, 128, 127, 128])\n",
      "Conv3x3, S1, P1        =>  torch.Size([1, 256, 127, 128])\n",
      "Decoder =================\n",
      "up_trans_1x18, S3, P0  =>  torch.Size([254, 256])\n",
      "up_conv_3x3, S1, P1    =>  torch.Size([256, 256])\n",
      "up_trans_2x2, S2, P0   =>  torch.Size([512, 512])\n",
      "up_conv_2x3, s1, p1    =>  torch.Size([512, 512])\n",
      "torch.Size([1, 1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "\n",
    "\n",
    "def single_conv(in_c, out_c):\n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv2d(in_c, out_c, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True))\n",
    "    return conv\n",
    "\n",
    "def double_conv1(in_c, out_c):\n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv2d(in_c, out_c, kernel_size=(3,2),padding=1 ,stride=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_c, out_c, kernel_size=(3,2),stride=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True))\n",
    "    return conv\n",
    "\n",
    "def double_conv2(in_c, out_c):\n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv2d(in_c, out_c, kernel_size=(3,3),padding=1 ,stride=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_c, out_c, kernel_size=(3,3), padding=1 ,stride=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True))\n",
    "    return conv\n",
    "\n",
    "\n",
    "def double_upconv2(in_c, out_c):\n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv2d(in_c, out_c, kernel_size=(3, 3),padding=1 ,stride=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_c, out_c, kernel_size=(3, 3),padding=1, stride=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True))\n",
    "    return conv\n",
    "\n",
    "def double_upconv1(in_c, out_c):\n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv2d(in_c, out_c, kernel_size=(2, 3),padding=1 ,stride=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_c, out_c, kernel_size=(2, 3),padding=1, stride=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True))\n",
    "    return conv\n",
    "\n",
    "def up_conv1(in_c, out_c):\n",
    "    conv = nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_c, out_c, kernel_size=(2, 2), stride=2))\n",
    "    return conv\n",
    "    \n",
    "def up_conv2(in_c, out_c):\n",
    "    conv = nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_c, out_c, kernel_size=(2,2), stride=2))\n",
    "    return conv\n",
    "\n",
    "class Attention_block(nn.Module):\n",
    "    def __init__(self,F_g,F_l,F_int):\n",
    "        super(Attention_block,self).__init__()\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "            )\n",
    "        \n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self,g,x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1+x1)\n",
    "        psi = self.psi(psi)\n",
    "\n",
    "        return x*psi\n",
    "\n",
    "class Att_UNet(nn.Module):\n",
    "    def __init__(self,img_ch=1,output_ch=1):\n",
    "        super(Att_UNet, self).__init__()\n",
    "        self.max_pool_2x2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.down_conv_1 = double_conv1(img_ch, 64)\n",
    "        self.down_conv_2 = double_conv2(64, 128)\n",
    "        self.down_conv_3 = double_conv2(128, 256)\n",
    "    \n",
    "        self.up_trans_1 = up_conv1(256, 128)\n",
    "        self.Att1 = Attention_block(F_g=128,F_l=128,F_int=64)\n",
    "        self.up_conv_1 = double_upconv1(256, 128)\n",
    "        \n",
    "        self.up_trans_2 = up_conv2(128, 64)\n",
    "        self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n",
    "        self.up_conv_2 = double_upconv2(128, 64)\n",
    "\n",
    "        self.out = nn.Conv2d(\n",
    "            in_channels=64,\n",
    "            out_channels=output_ch,\n",
    "            kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "    def forward(self, image):\n",
    "        # encoder\n",
    "        print(\"Input Image            => \", image.size())\n",
    "        print(\"Encoder =================\")\n",
    "        x1 = self.down_conv_1(image)\n",
    "        print(\"Conv3x2, S1, P1        => \", x1.size())\n",
    "        x2 = self.max_pool_2x2(x1)\n",
    "        print(\"max_pool_2x1           => \", x2.size())\n",
    "        x3 = self.down_conv_2(x2)\n",
    "        print(\"Conv3x3, S1, P1        => \", x3.size())\n",
    "        x4 = self.max_pool_2x2(x3)\n",
    "        print(\"max_pool_2x1           => \", x4.size())\n",
    "        x5 = self.down_conv_3(x4)\n",
    "        print(\"Conv3x3, S1, P1        => \", x5.size())\n",
    "        \n",
    "        \n",
    "        # decoder\n",
    "        print(\"Decoder =================\")\n",
    "        x = self.up_trans_1(x5)\n",
    "        print(\"up_trans_1x18, S3, P0  => \", x.size()[2:4])\n",
    "        x3 = nn.functional.interpolate(x3, (x.size()[2], x.size()[3]))\n",
    "        x3 = self.Att1(g=x,x=x3)\n",
    "        x = self.up_conv_1(torch.cat([x, x3], 1))\n",
    "        print(\"up_conv_3x3, S1, P1    => \", x.size()[2:4])\n",
    "\n",
    "        x = self.up_trans_2(x)\n",
    "        print(\"up_trans_2x2, S2, P0   => \", x.size()[2:4])\n",
    "        x1 = nn.functional.interpolate(x1, (x.size()[2], x.size()[3]))\n",
    "        x1 = self.Att2(g=x,x=x1)\n",
    "        x = self.up_conv_2(torch.cat([x, x1], 1))\n",
    "        print(\"up_conv_2x3, s1, p1    => \", x.size()[2:4])\n",
    "        # output\n",
    "        x = self.out(x)\n",
    "        print(x.size())\n",
    "        return x\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image = torch.rand(1, 3, 512, 512)\n",
    "    model = Att_UNet(img_ch=3,output_ch=1)\n",
    "    model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Input Image            =>  torch.Size([1, 3, 512, 512])\n",
      "Encoder =================\n",
      "Conv3x2, S1, P1        =>  torch.Size([1, 64, 512, 512])\n",
      "max_pool_2x1           =>  torch.Size([1, 64, 256, 256])\n",
      "Conv3x3, S1, P1        =>  torch.Size([1, 128, 256, 256])\n",
      "max_pool_2x1           =>  torch.Size([1, 128, 128, 128])\n",
      "Conv3x3, S1, P1        =>  torch.Size([1, 256, 128, 128])\n",
      "Decoder =================\n",
      "up_trans_1x18, S3, P0  =>  torch.Size([1, 128, 256, 256])\n",
      "up_conv_3x3, S1, P1    =>  torch.Size([1, 128, 256, 256])\n",
      "up_trans_2x2, S2, P0   =>  torch.Size([1, 64, 512, 512])\n",
      "up_conv_2x3, s1, p1    =>  torch.Size([1, 64, 512, 512])\n",
      "torch.Size([1, 1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "\n",
    "def single_conv(in_c, out_c):\n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv2d(in_c, out_c, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True))\n",
    "    return conv\n",
    "\n",
    "def double_conv1(in_c, out_c):\n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv2d(in_c, out_c, kernel_size=(3,2),padding=1 ,stride=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_c, out_c, kernel_size=(3,2),stride=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True))\n",
    "    return conv\n",
    "\n",
    "def double_conv2(in_c, out_c):\n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv2d(in_c, out_c, kernel_size=(3,3),padding=1 ,stride=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_c, out_c, kernel_size=(3,3), padding=1 ,stride=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True))\n",
    "    return conv\n",
    "\n",
    "\n",
    "def up_conv1(in_c, out_c):\n",
    "    conv = nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_c, out_c, kernel_size=(2, 2), stride=2))\n",
    "    return conv\n",
    "    \n",
    "def up_conv2(in_c, out_c):\n",
    "    conv = nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_c, out_c, kernel_size=(2,2), stride=2))\n",
    "    return conv\n",
    "\n",
    "\n",
    "class Recurrent_block(nn.Module):\n",
    "    def __init__(self,ch_out,t=2):\n",
    "        super(Recurrent_block,self).__init__()\n",
    "        self.t = t\n",
    "        self.ch_out = ch_out\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "\t\t    nn.BatchNorm2d(ch_out),\n",
    "\t\t\tnn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        for i in range(self.t):\n",
    "\n",
    "            if i==0:\n",
    "                x1 = self.conv(x)\n",
    "            \n",
    "            x1 = self.conv(x+x1)\n",
    "        return x1\n",
    "\n",
    "class RRCNN_block(nn.Module):\n",
    "    def __init__(self,ch_in,ch_out,t=2):\n",
    "        super(RRCNN_block,self).__init__()\n",
    "        self.RCNN = nn.Sequential(\n",
    "            Recurrent_block(ch_out,t=t),\n",
    "            Recurrent_block(ch_out,t=t)\n",
    "        )\n",
    "        self.Conv_1x1 = nn.Conv2d(ch_in,ch_out,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.Conv_1x1(x)\n",
    "        x1 = self.RCNN(x)\n",
    "        return x+x1\n",
    "\n",
    "\n",
    "class Attention_block(nn.Module):\n",
    "    def __init__(self,F_g,F_l,F_int):\n",
    "        super(Attention_block,self).__init__()\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "            )\n",
    "        \n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self,g,x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1+x1)\n",
    "        psi = self.psi(psi)\n",
    "\n",
    "        return x*psi\n",
    "\n",
    "\n",
    "\n",
    "class Att_R2U(nn.Module):\n",
    "    def __init__(self,img_ch=1,output_ch=1,t=2):\n",
    "        super(Att_R2U, self).__init__()\n",
    "        self.max_pool_2x2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.RCNN1 = RRCNN_block(img_ch, 64, t=t)\n",
    "        self.RCNN2 = RRCNN_block(64, 128, t=t)\n",
    "        self.RCNN3 = RRCNN_block(128, 256, t=t)\n",
    "\n",
    "        self.up_trans_1 = up_conv1(256, 128)\n",
    "        self.Att1 = Attention_block(F_g=128,F_l=128,F_int=64)\n",
    "        self.Up_RRCNN1 = RRCNN_block(256, 128,t=t)\n",
    "        \n",
    "        self.up_trans_2 = up_conv2(128, 64)\n",
    "        self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n",
    "        self.Up_RRCNN2 = RRCNN_block(128, 64,t=t)\n",
    "\n",
    "        self.out = nn.Conv2d(\n",
    "            in_channels=64,\n",
    "            out_channels=output_ch,\n",
    "            kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "    def forward(self, image):\n",
    "        # encoder\n",
    "        print(\"Input Image            => \", image.size())\n",
    "        print(\"Encoder =================\")\n",
    "        x1 = self.RCNN1(image)\n",
    "        print(\"Conv3x2, S1, P1        => \", x1.size())\n",
    "        x2 = self.max_pool_2x2(x1)\n",
    "        print(\"max_pool_2x1           => \", x2.size())\n",
    "        x3 = self.RCNN2(x2)\n",
    "        print(\"Conv3x3, S1, P1        => \", x3.size())\n",
    "        x4 = self.max_pool_2x2(x3)\n",
    "        print(\"max_pool_2x1           => \", x4.size())\n",
    "        x5 = self.RCNN3(x4)\n",
    "        print(\"Conv3x3, S1, P1        => \", x5.size())\n",
    "        \n",
    "        \n",
    "        # decoder\n",
    "        print(\"Decoder =================\")\n",
    "        x = self.up_trans_1(x5)\n",
    "        print(\"up_trans_1x18, S3, P0  => \", x.size())\n",
    "        x3 = nn.functional.interpolate(x3, (x.size()[2], x.size()[3]))\n",
    "        x3 = self.Att1(g=x,x=x3)\n",
    "        x = self.Up_RRCNN1(torch.cat([x, x3], 1))\n",
    "        print(\"up_conv_3x3, S1, P1    => \", x.size())\n",
    "\n",
    "        x = self.up_trans_2(x)\n",
    "        print(\"up_trans_2x2, S2, P0   => \", x.size())\n",
    "        x1 = nn.functional.interpolate(x1, (x.size()[2], x.size()[3]))\n",
    "        x1 = self.Att2(g=x,x=x1)\n",
    "        x = self.Up_RRCNN2(torch.cat([x, x1], 1))\n",
    "        print(\"up_conv_2x3, s1, p1    => \", x.size())\n",
    "        # output\n",
    "        x = self.out(x)\n",
    "        print(x.size())\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"start\")\n",
    "    image = torch.rand(1, 3, 512, 512)\n",
    "    model = Att_R2U(img_ch=3)\n",
    "    model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
